# ğŸ§  Fact Generator

Fine-tune a small language model (GPT-2 or Phi-2) on a list of simple, newline-separated "facts". Generate new facts via a local web interface, retrain the model, and explore generation settingsâ€”all from your own machine.

---

## ğŸ“¦ Whatâ€™s Included

- `facts.txt` â€“ Your dataset (one fact per line)
- `prepare_dataset.py` â€“ Converts `facts.txt` into model-ready format
- `train_fact_model.py` â€“ Trains the model (GPT-2 or Phi-2)
- `fact_server.py` â€“ Runs a FastAPI server for generation, retraining, stats
- `index.html` â€“ Minimal web UI for fact generation and model control
- `model-config.json` â€“ Touch this file to trigger a live reload
- Setup scripts: `setup.sh`, `setup.ps1`, `retrain.sh`, `retrain.ps1`
- Docker support: `Dockerfile`, `docker-compose.yml`

---

## ğŸ§° Requirements

- Python 3.10+
- pip or Docker
- A GPU is recommended (see below)

---

## âš™ï¸ Supported Hardware

### âœ… NVIDIA GPU (CUDA)

Fully supported. Used automatically if detected.

### ğŸŸ  AMD GPU (ROCm/CPU)

- This setup automatically falls back to CPU if CUDA is unavailable.
- Compatible with ROCm-based PyTorch builds, but does not require them.
- All functionality works on CPU, but will be **slower**, especially for Phi-2.

Verify which device is in use:
```python
print("Using device:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU")
```

---

## ğŸªŸ Windows Setup

### ğŸ”§ Without Docker (Command Line)

1. Run PowerShell:
   ```powershell
   Set-ExecutionPolicy Bypass -Scope Process -Force
   .\setup.ps1
   ```

2. Activate the virtual environment:
   ```powershell
   .env\Scripts\Activate.ps1
   ```

3. Train and run:
   ```powershell
   python prepare_dataset.py
   python train_fact_model.py
   python fact_server.py
   ```

4. Open `index.html` in your browser.

---

### ğŸ³ With Docker

1. Install [Docker Desktop](https://www.docker.com/products/docker-desktop)

2. Build and run:
   ```powershell
   docker-compose up --build
   ```

3. Open `index.html` in your browser.

---

## ğŸ§ Linux Setup

### ğŸ”§ Without Docker (Command Line)

1. Set up the environment:
   ```bash
   chmod +x setup.sh
   ./setup.sh
   source venv/bin/activate
   ```

2. Train and run:
   ```bash
   python prepare_dataset.py
   python train_fact_model.py
   python fact_server.py
   ```

3. Open `index.html` in your browser.

---

### ğŸ³ With Docker

1. Build and run:
   ```bash
   docker-compose up --build
   ```

2. Open `index.html` in your browser.

---

## ğŸ§ª Features

- ğŸ” Live reload after training (no restart needed)
- ğŸ’¬ Generate new facts from custom prompts
- ğŸ“ˆ Live logs from retraining (via server-sent events)
- ğŸŒ“ Dark-mode web UI (zero dependencies)
- ğŸ”§ Choose model (`gpt2` or `phi2`) before training
- ğŸ§  Use sliders for temperature, token count, and more (optional extensions)
- ğŸ–¥ Works with NVIDIA GPUs, AMD GPUs (ROCm), or CPU fallback

---

## âœ… Usage Tips

- To add new facts: edit `facts.txt`, then click **Retrain** in the UI
- To change model: set `MODEL_TYPE=gpt2` or `MODEL_TYPE=phi2` in the environment or UI
- To force reload manually: touch `model-config.json` or click **Reload** in the UI
- To reset output: refresh the browser or clear the UI fields

---

## âš ï¸ Notes

- Phi-2 training on CPU may take hours to completeâ€”use GPT-2 if resources are limited
- Checkpoints are saved to `./fact-model/`
- You can change the training cadence using OS-level scheduling (e.g. `cron`, `Task Scheduler`)

---

Enjoy generating your own knowledge base! ğŸ§ âœ¨
