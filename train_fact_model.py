fp16=torch.cuda.is_available(),  # Use AMP only with CUDA